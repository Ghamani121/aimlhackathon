{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaYPjNWNzJ77"
   },
   "source": [
    "# Install necessary libraries (run in Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIZl1QMzWroy",
    "outputId": "b91af1c6-4523-4e83-9446-089936223128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-jvpkwmyq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-jvpkwmyq\n",
      "  Resolved https://github.com/openai/whisper.git to commit 271445b2f24f00f8175c4fb7ae91876f7451dfc1\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.10.1)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.0+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.6)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.8.0)\n",
      "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git transformers pymongo sentence-transformers pydub\n",
    "!apt-get install -y ffmpeg  # For handling audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S8nlnhczPJb"
   },
   "source": [
    "# Drive access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fuMocxyqIb11",
    "outputId": "12917570-e69c-4fc5-cfac-cfff91ff7d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xj9UZC4ZzUjc"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ga8HmfO_WvLq"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer, T5ForConditionalGeneration, T5Tokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "from pymongo import MongoClient\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DJe1xOZzcwc"
   },
   "source": [
    "# Model Import and choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k673FZCbW5jy",
    "outputId": "3c3b384b-0ade-434c-99e3-3523e01abad3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Load models (ensure GPU is enabled in Colab runtime settings)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Whisper model for transcription\n",
    "whisper_model = whisper.load_model(\"large\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxB8WZk8zhxS"
   },
   "source": [
    "# MongoDB Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R1ubQwt0Ix9"
   },
   "source": [
    "## MongoDB connection setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThSpBW2ux9cN"
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "def get_mongo_client(uri):\n",
    "    try:\n",
    "        client = MongoClient(uri)\n",
    "        print(\"Connected to MongoDB successfully.\")\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to MongoDB: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcLQwoQA0MVD"
   },
   "source": [
    "## MongoDB connection URI (replace with your own URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TSKlDsnyB0s",
    "outputId": "9b60744b-99fc-4d7e-d49a-57c5b5a70870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB successfully.\n"
     ]
    }
   ],
   "source": [
    "# Replace with your MongoDB URI\n",
    "mongodb_uri = \"mongodb+srv://python:1234567890@cluster.kvnyt.mongodb.net\"\n",
    "client = get_mongo_client(mongodb_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVY2ZX630QsO"
   },
   "source": [
    "## Database and collection setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ibMyqWwK0Tc5"
   },
   "outputs": [],
   "source": [
    "db = client['sandalquest']\n",
    "collection = db['transcriptions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Gs2hwlz0Vsc"
   },
   "source": [
    "## Function to save the merged transcription to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUd7J7BryR7N"
   },
   "outputs": [],
   "source": [
    "def save_to_mongodb(metadata):\n",
    "    try:\n",
    "        collection.insert_one(metadata)\n",
    "        print(f\"Saved merged transcription for {\n",
    "              metadata['filename']} to MongoDB.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to MongoDB: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EV4QamH_0coR"
   },
   "source": [
    "## Check if the file is already processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "N_qpIcoz0Gjt"
   },
   "outputs": [],
   "source": [
    "def is_file_processed(filename):\n",
    "    try:\n",
    "        return collection.find_one({\"filename\": filename}) is not None\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking file in MongoDB: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2tuvgxWzmUY"
   },
   "source": [
    "# Function to split audio based on file size (20 MB chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unM50snjW8p0"
   },
   "outputs": [],
   "source": [
    "def split_audio_by_size(file_path, max_size_mb=20):\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(file_path)\n",
    "        file_size_bytes = os.path.getsize(file_path)\n",
    "        max_size_bytes = max_size_mb * 1024 * 1024\n",
    "\n",
    "        # Calculate number of chunks needed\n",
    "        num_chunks = math.ceil(file_size_bytes / max_size_bytes)\n",
    "        chunk_length_ms = len(audio) // num_chunks\n",
    "\n",
    "        # Split the audio into chunks\n",
    "        chunks = make_chunks(audio, chunk_length_ms)\n",
    "        print(f\"Split audio into {len(chunks)} chunks based on size.\")\n",
    "        return chunks\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error splitting audio by size: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVM3YZqWzrLv"
   },
   "source": [
    "# Function for Kannada transcription using Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-6Ge4QjyWgw"
   },
   "outputs": [],
   "source": [
    "def transcribe_audio_kannada(audio_path):\n",
    "    try:\n",
    "        print(\"Transcribing in progress...\")\n",
    "        transcription = whisper_model.transcribe(\n",
    "            audio_path, language=\"kn\")['text']\n",
    "        return transcription\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZv3rjIGztL-"
   },
   "source": [
    "# Process audio files and merge transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vh8QJGRuXEbs"
   },
   "outputs": [],
   "source": [
    "def process_audio_files(directory_path):\n",
    "    file_list = os.listdir(directory_path)\n",
    "    process_index = 1\n",
    "\n",
    "    for filename in file_list:\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Skip non-audio files\n",
    "        if not filename.endswith(\".mp3\"):\n",
    "            continue\n",
    "\n",
    "        # Check if the file is already processed\n",
    "        if is_file_processed(filename):\n",
    "            print(f\"File {filename} already processed. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"Processing file {process_index}: {filename}\")\n",
    "            chunks = split_audio_by_size(file_path, max_size_mb=20)\n",
    "            merged_transcription = \"\"\n",
    "\n",
    "            # Transcribe each chunk and merge the results\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                print(f\"Transcribing chunk {\n",
    "                      i + 1}/{len(chunks)} of file {filename}...\")\n",
    "                chunk.export(\"temp_chunk.wav\", format=\"wav\")\n",
    "                kannada_text = transcribe_audio_kannada(\"temp_chunk.wav\")\n",
    "                merged_transcription += kannada_text + \" \"\n",
    "\n",
    "            # Prepare metadata for the merged transcription\n",
    "            metadata = {\n",
    "                'file_index': process_index,\n",
    "                'filename': filename,\n",
    "                'merged_transcription': merged_transcription.strip(),\n",
    "                'timestamp': datetime.datetime.utcnow(),\n",
    "                'file_path': file_path,\n",
    "                'file_size': os.path.getsize(file_path),\n",
    "                'audio_format': filename.split(\".\")[-1],\n",
    "                'duration_ms': len(AudioSegment.from_file(file_path))\n",
    "            }\n",
    "\n",
    "            # Save the merged transcription to MongoDB\n",
    "            save_to_mongodb(metadata)\n",
    "            print(f\"Finished processing file {process_index}: {filename}\")\n",
    "\n",
    "            # Increment the process index for the next file\n",
    "            process_index += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"All files processed or skipped successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_O105aT_zuem"
   },
   "source": [
    "# Step 1: Unzipping and processing audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5kpzDfbXHXV",
    "outputId": "5d19df14-033b-4d45-dc2a-d06a62d5d760"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are already extracted.\n",
      "Dataset extraction and verification completed.\n",
      "Final list of extracted files:\n",
      "SandalWoodNewsStories_200.mp3\n",
      "SandalWoodNewsStories_282.mp3\n",
      "SandalWoodNewsStories_239.mp3\n",
      "SandalWoodNewsStories_295.mp3\n",
      "SandalWoodNewsStories_230.mp3\n",
      "SandalWoodNewsStories_148.mp3\n",
      "SandalWoodNewsStories_46.mp3\n",
      "SandalWoodNewsStories_167.mp3\n",
      "SandalWoodNewsStories_63.mp3\n",
      "SandalWoodNewsStories_298.mp3\n",
      "SandalWoodNewsStories_176.mp3\n",
      "SandalWoodNewsStories_223.mp3\n",
      "SandalWoodNewsStories_168.mp3\n",
      "SandalWoodNewsStories_156.mp3\n",
      "SandalWoodNewsStories_297.mp3\n",
      "SandalWoodNewsStories_249.mp3\n",
      "SandalWoodNewsStories_215.mp3\n",
      "SandalWoodNewsStories_211.mp3\n",
      "SandalWoodNewsStories_158.mp3\n",
      "SandalWoodNewsStories_23.mp3\n",
      "SandalWoodNewsStories_175.mp3\n",
      "SandalWoodNewsStories_146.mp3\n",
      "SandalWoodNewsStories_173.mp3\n",
      "SandalWoodNewsStories_42.mp3\n",
      "SandalWoodNewsStories_52.mp3\n",
      "SandalWoodNewsStories_112.mp3\n",
      "SandalWoodNewsStories_43.mp3\n",
      "SandalWoodNewsStories_181.mp3\n",
      "SandalWoodNewsStories_306.mp3\n",
      "SandalWoodNewsStories_169.mp3\n",
      "SandalWoodNewsStories_36.mp3\n",
      "SandalWoodNewsStories_99.mp3\n",
      "SandalWoodNewsStories_283.mp3\n",
      "SandalWoodNewsStories_304.mp3\n",
      "SandalWoodNewsStories_159.mp3\n",
      "SandalWoodNewsStories_184.mp3\n",
      "SandalWoodNewsStories_144.mp3\n",
      "SandalWoodNewsStories_172.mp3\n",
      "SandalWoodNewsStories_197.mp3\n",
      "SandalWoodNewsStories_179.mp3\n",
      "SandalWoodNewsStories_49.mp3\n",
      "SandalWoodNewsStories_89.mp3\n",
      "SandalWoodNewsStories_174.mp3\n",
      "SandalWoodNewsStories_280.mp3\n",
      "SandalWoodNewsStories_35.mp3\n",
      "SandalWoodNewsStories_278.mp3\n",
      "SandalWoodNewsStories_98.mp3\n",
      "SandalWoodNewsStories_305.mp3\n",
      "SandalWoodNewsStories_171.mp3\n",
      "SandalWoodNewsStories_6.mp3\n",
      "SandalWoodNewsStories_257.mp3\n",
      "SandalWoodNewsStories_45.mp3\n",
      "SandalWoodNewsStories_287.mp3\n",
      "SandalWoodNewsStories_2.mp3\n",
      "SandalWoodNewsStories_284.mp3\n",
      "SandalWoodNewsStories_242.mp3\n",
      "SandalWoodNewsStories_1.mp3\n",
      "SandalWoodNewsStories_296.mp3\n",
      "SandalWoodNewsStories_229.mp3\n",
      "SandalWoodNewsStories_107.mp3\n",
      "SandalWoodNewsStories_303.mp3\n",
      "SandalWoodNewsStories_33.mp3\n",
      "SandalWoodNewsStories_53.mp3\n",
      "SandalWoodNewsStories_191.mp3\n",
      "SandalWoodNewsStories_279.mp3\n",
      "SandalWoodNewsStories_291.mp3\n",
      "SandalWoodNewsStories_299.mp3\n",
      "SandalWoodNewsStories_9.mp3\n",
      "SandalWoodNewsStories_41.mp3\n",
      "SandalWoodNewsStories_286.mp3\n",
      "SandalWoodNewsStories_294.mp3\n",
      "All 71 files are extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to your dataset in Google Drive\n",
    "zip_path = \"/content/drive/MyDrive/SandalWoonDatasets.zip\"\n",
    "# Path where files will be extracted\n",
    "extracted_path = \"/content/drive/MyDrive/SandalWood\"\n",
    "\n",
    "# Step 1: Create the extraction folder if it doesn't exist\n",
    "os.makedirs(extracted_path, exist_ok=True)\n",
    "\n",
    "# Helper function to list files in a directory\n",
    "\n",
    "\n",
    "def list_files_in_directory(directory_path):\n",
    "    extracted_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            extracted_files.append(os.path.relpath(\n",
    "                os.path.join(root, file), directory_path))\n",
    "    return extracted_files\n",
    "\n",
    "\n",
    "# Step 2: Check and extract files\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_files = zip_ref.namelist()  # List of all files in the ZIP archive\n",
    "\n",
    "    # List existing files in the extracted directory\n",
    "    extracted_files = list_files_in_directory(extracted_path)\n",
    "\n",
    "    # Find missing files\n",
    "    missing_files = [file for file in zip_files if file not in extracted_files]\n",
    "\n",
    "    if missing_files:\n",
    "        print(f\"Missing {len(missing_files)\n",
    "                         } files. Re-extracting missing files...\")\n",
    "\n",
    "        # Re-extract only missing files\n",
    "        for file in missing_files:\n",
    "            try:\n",
    "                zip_ref.extract(file, extracted_path)\n",
    "                print(f\"Re-extracted file: {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting file {file}: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(\"All files are already extracted.\")\n",
    "\n",
    "print(\"Dataset extraction and verification completed.\")\n",
    "\n",
    "# Verify extraction\n",
    "print(\"Final list of extracted files:\")\n",
    "for file in list_files_in_directory(extracted_path):\n",
    "    print(file)\n",
    "\n",
    "# Summary\n",
    "total_files_in_zip = len(zip_files)\n",
    "total_extracted_files = len(list_files_in_directory(extracted_path))\n",
    "\n",
    "if total_files_in_zip == total_extracted_files:\n",
    "    print(f\"All {total_files_in_zip} files are extracted successfully.\")\n",
    "else:\n",
    "    print(f\"Extraction completed with {\n",
    "          total_extracted_files}/{total_files_in_zip} files available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GG5xuEjwzyEf"
   },
   "source": [
    "# Step 2: Process the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGG-D54J--eP",
    "outputId": "d7265711-c4c5-434f-c562-10b779b43210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File SandalWoodNewsStories_200.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_282.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_239.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_295.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_230.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_148.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_46.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_167.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_63.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_298.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_176.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_223.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_168.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_156.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_297.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_249.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_215.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_211.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_158.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_23.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_175.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_146.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_173.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_42.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_52.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_112.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_43.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_181.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_306.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_169.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_36.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_99.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_283.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_304.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_159.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_184.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_144.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_172.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_197.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_179.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_49.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_89.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_174.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_280.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_35.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_278.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_98.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_305.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_171.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_6.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_257.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_45.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_287.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_2.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_284.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_242.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_1.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_296.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_229.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_107.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_303.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_33.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_53.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_191.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_279.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_291.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_299.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_9.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_41.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_286.mp3 already processed. Skipping.\n",
      "File SandalWoodNewsStories_294.mp3 already processed. Skipping.\n",
      "All files processed or skipped successfully.\n"
     ]
    }
   ],
   "source": [
    "process_audio_files(extracted_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
